{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt   \n",
    "\n",
    "def load_sample_dataset():\n",
    "    \"\"\"Load a ndarray sample dataset and an array of labels for testing AdaBoost\"\"\"\n",
    "    dataset = np.array([[1., 2.1], [2., 1.1], [1.3, 1.], [1., 1.], [2., 1.]])\n",
    "    labels = np.array([1.0, 1.0, -1.0, -1.0, 1.0])\n",
    "    return dataset, labels\n",
    "\n",
    "def build_stump(dataset, labels, D):\n",
    "    \"\"\"Build a single stump to classify the dataset and calculate the weighted error of the stump.\n",
    "    \n",
    "    Args:\n",
    "        dataset: ndarray of inputs. Shape (m, n)\n",
    "        labels: array of labels. Shape (m,)\n",
    "        D: array of weights on each example. Shape (m,)\n",
    "    Returns:\n",
    "        stump: a dict containing splitting feature, threshold, inequality\n",
    "        err: the weighted err of the stump on dataset\n",
    "        pred: array of predictions on dataset\n",
    "    \"\"\"\n",
    "    m, n = dataset.shape\n",
    "    \n",
    "    stump = {}\n",
    "    err = float('inf')\n",
    "    pred = np.array(m)\n",
    "\n",
    "    steps = 10\n",
    "\n",
    "    # Loop over each feature with a stepsize to find min error sum\n",
    "    for i in range(n):\n",
    "        xi_min = dataset[:, i].min()\n",
    "        xi_max = dataset[:, i].max()\n",
    "        step_size = (xi_max - xi_min) / steps\n",
    "\n",
    "        for j in range(-1, steps + 1):\n",
    "            for inequal in ['lt', 'gt']:\n",
    "                thresh = xi_min + step_size * j\n",
    "                pred_i = stump_classify(dataset, i, thresh, inequal)\n",
    "\n",
    "                err_i = (pred_i != labels).astype(int)\n",
    "                weighted_err_i = D.dot(err_i)\n",
    "#                 print('The stump splits on dim: {} with threshold: {}, the weighted error is {}'.format(i, thresh, weighted_err_i))\n",
    "\n",
    "                if weighted_err_i < err:\n",
    "                    err = weighted_err_i\n",
    "                    stump['inequal'] = inequal\n",
    "                    stump['dim'] = i\n",
    "                    stump['thresh'] = thresh\n",
    "                    pred = pred_i\n",
    "    \n",
    "    return stump, err, pred\n",
    "\n",
    "def stump_classify(dataset, dim, thresh, inequal):\n",
    "    \"\"\"Classify a dataset based on the stump parameters as inputs.\n",
    "\n",
    "    Args: \n",
    "        dataset: ndarray of inputs. Shape (m, n)\n",
    "        dim: the feature dimension split on\n",
    "        thresh: threshold for splitting\n",
    "        inequal: lt - less than. gt - greater than\n",
    "    Returns:\n",
    "        pred: array of predictions on dataset\n",
    "    \"\"\"\n",
    "    pred = np.ones(dataset.shape[0])\n",
    "\n",
    "    if inequal == 'lt':\n",
    "        pred[dataset[:, dim] <= thresh] = -1\n",
    "    else:\n",
    "        pred[dataset[:, dim] > thresh] = -1\n",
    "\n",
    "    return pred\n",
    "\n",
    "def adaboost_train(dataset, labels, max_iter=40):\n",
    "    \"\"\"Train an Adaptive Boosting model using stumps on dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset: ndarray of inputs. Shape (m, n)\n",
    "        labels: array of labels. Shape (m,)\n",
    "        max_iter: maximum iterations allowed for learning\n",
    "    Returns:\n",
    "        models: a list of stump classifier, each stump contains a weighting parameter alpha\n",
    "    \"\"\"\n",
    "    m, n = dataset.shape\n",
    "    D = np.ones(m) / m\n",
    "    models = []\n",
    "    aggr_pred = np.zeros(m)\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        stump_k, err_k, pred_k = build_stump(dataset, labels, D)\n",
    "        alpha_k = 0.5 * np.log((1 - err_k) / max(err_k, 1e-16))\n",
    "#         print('Predicted result: ', pred_k)\n",
    "\n",
    "        expon = np.exp(-alpha_k * labels * pred_k)\n",
    "        D = (D * expon) / (D.dot(expon))\n",
    "\n",
    "        stump_k['alpha'] = alpha_k\n",
    "        models.append(stump_k)\n",
    "\n",
    "        aggr_pred += alpha_k * pred_k\n",
    "        aggr_err = (np.sign(aggr_pred) != labels).sum()\n",
    "        print('Iteration: {}, the error rate is {}'.format(k, aggr_err / m))\n",
    "        if aggr_err == 0:\n",
    "            break\n",
    "\n",
    "    return models, aggr_pred\n",
    "\n",
    "def adaboost_classify(dataset, models):\n",
    "    \"\"\"Classify a dataset given adaboost models.\n",
    "    \n",
    "    Args:\n",
    "        dataset: ndarray of inputs. Shape (m, n)\n",
    "        models: a list of stump classifier, each stump contains a weighting parameter alpha\n",
    "    Return:\n",
    "        pred: array of predicted labels for input dataset\n",
    "    \"\"\"\n",
    "    m = dataset.shape[0]\n",
    "    pred = np.zeros(m)\n",
    "\n",
    "    for model in models:\n",
    "        pred += model['alpha'] * stump_classify(dataset, model['dim'], model['thresh'], model['inequal'])\n",
    "\n",
    "    return np.sign(pred)\n",
    "\n",
    "def load_dataset(path):\n",
    "    \"\"\"From path load data into a ndarray of x matrix and an array of labels.\n",
    "    \n",
    "    Args:\n",
    "        path: the path to the txt file\n",
    "    Returns:\n",
    "        dataset: ndarray containing feature vectors\n",
    "        labels: array containing labels\n",
    "    \"\"\"\n",
    "    # Load one row to get size \n",
    "    with open(path, 'r') as fr:\n",
    "        first_row = fr.readline().strip().split('\\t')\n",
    "        \n",
    "    x_cols = [i for i in range(len(first_row) - 1)]\n",
    "    l_col = [len(first_row) - 1]\n",
    "    \n",
    "    dataset = np.loadtxt(path, delimiter='\\t', usecols=x_cols)\n",
    "    labels = np.loadtxt(path, delimiter='\\t', usecols=l_col)\n",
    "    return dataset, labels\n",
    "\n",
    "def plot_ROC(aggr_pred, labels):\n",
    "    \"\"\"Plot the ROC of a model with it's predicted value and labels.\n",
    "    \n",
    "    Args:\n",
    "        aggr_pred: array of the predicted strengths of examples. Shape (m,)\n",
    "        labels: array of labele. Shape (m,)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    cur_pos = [0.0, 0.0]    # current position\n",
    "    y_sum = 0\n",
    "\n",
    "    p_num = (labels == 1).sum() # num of positive labels\n",
    "    v_stepsize = 1 / p_num      # step size along true positive axis\n",
    "    \n",
    "    n_num = labels.shape[0] - p_num    # num of negative labels\n",
    "    h_stepsize = 1 / n_num      # step size along false positive axis\n",
    "   \n",
    "    desc_indices = np.argsort(-aggr_pred)   # get the index of descending prediction strength\n",
    "    for i in list(desc_indices):\n",
    "        if labels[i] == 1:\n",
    "            x = cur_pos[0]\n",
    "            y = cur_pos[1] + v_stepsize\n",
    "        else:\n",
    "            x = cur_pos[0] + h_stepsize\n",
    "            y = cur_pos[1]\n",
    "            y_sum += y\n",
    "\n",
    "        ax.plot([cur_pos[0], x], [cur_pos[1], y], c='b')  # ax.plot([x list], [y list])\n",
    "        cur_pos = [x, y]\n",
    "#         print(cur_pos)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'b--')  # plot the line of random selection\n",
    "    ax.axis([0, 1, 0, 1])   # ax.axis([xmin, xmax, ymin, ymax])\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.savefig('adaboost_horsecolic_roc.png')\n",
    "\n",
    "    AUC = y_sum * h_stepsize\n",
    "    print('The Area Under Curve is {}'.format(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, the error rate is 0.2\n",
      "Iteration: 1, the error rate is 0.2\n",
      "Iteration: 2, the error rate is 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for sample dataset\n",
    "dataset, labels = load_sample_dataset()\n",
    "D = np.ones(5) / 5\n",
    "models, aggr_pred = adaboost_train(dataset, labels)\n",
    "adaboost_classify(np.array([[1, 2.1]]), models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, the error rate is 0.2842809364548495\n",
      "Iteration: 1, the error rate is 0.2842809364548495\n",
      "Iteration: 2, the error rate is 0.24749163879598662\n",
      "Iteration: 3, the error rate is 0.24749163879598662\n",
      "Iteration: 4, the error rate is 0.25418060200668896\n",
      "Iteration: 5, the error rate is 0.2408026755852843\n",
      "Iteration: 6, the error rate is 0.2408026755852843\n",
      "Iteration: 7, the error rate is 0.22073578595317725\n",
      "Iteration: 8, the error rate is 0.24749163879598662\n",
      "Iteration: 9, the error rate is 0.23076923076923078\n",
      "Iteration: 10, the error rate is 0.2408026755852843\n",
      "Iteration: 11, the error rate is 0.2140468227424749\n",
      "Iteration: 12, the error rate is 0.22742474916387959\n",
      "Iteration: 13, the error rate is 0.21739130434782608\n",
      "Iteration: 14, the error rate is 0.22073578595317725\n",
      "Iteration: 15, the error rate is 0.21739130434782608\n",
      "Iteration: 16, the error rate is 0.22408026755852842\n",
      "Iteration: 17, the error rate is 0.22408026755852842\n",
      "Iteration: 18, the error rate is 0.23076923076923078\n",
      "Iteration: 19, the error rate is 0.22408026755852842\n",
      "Iteration: 20, the error rate is 0.2140468227424749\n",
      "Iteration: 21, the error rate is 0.20735785953177258\n",
      "Iteration: 22, the error rate is 0.22408026755852842\n",
      "Iteration: 23, the error rate is 0.22408026755852842\n",
      "Iteration: 24, the error rate is 0.2140468227424749\n",
      "Iteration: 25, the error rate is 0.22073578595317725\n",
      "Iteration: 26, the error rate is 0.2040133779264214\n",
      "Iteration: 27, the error rate is 0.20735785953177258\n",
      "Iteration: 28, the error rate is 0.21070234113712374\n",
      "Iteration: 29, the error rate is 0.21739130434782608\n",
      "Iteration: 30, the error rate is 0.21070234113712374\n",
      "Iteration: 31, the error rate is 0.21739130434782608\n",
      "Iteration: 32, the error rate is 0.20735785953177258\n",
      "Iteration: 33, the error rate is 0.21070234113712374\n",
      "Iteration: 34, the error rate is 0.20735785953177258\n",
      "Iteration: 35, the error rate is 0.20735785953177258\n",
      "Iteration: 36, the error rate is 0.19732441471571907\n",
      "Iteration: 37, the error rate is 0.19063545150501673\n",
      "Iteration: 38, the error rate is 0.20066889632107024\n",
      "Iteration: 39, the error rate is 0.19732441471571907\n",
      "Test error rate is 0.19402985074626866\n"
     ]
    }
   ],
   "source": [
    "# Test for horse colic dataset\n",
    "x_train, y_train = load_dataset('horseColicTraining2.txt')\n",
    "x_test, y_test = load_dataset('horseColicTest2.txt')\n",
    "\n",
    "stumps, aggr_pred = adaboost_train(x_train, y_train)\n",
    "pred_test = adaboost_classify(x_test, stumps)\n",
    "err_rate_test = (pred_test != y_test).sum() / x_test.shape[0]\n",
    "print('Test error rate is {}'.format(err_rate_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Area Under Curve is 0.8919583991085535\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ROC(aggr_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
