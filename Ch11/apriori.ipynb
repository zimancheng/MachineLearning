{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_sample_data():\n",
    "    dataset = [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
    "    return list(map(set, dataset))\n",
    "\n",
    "def get_c1(dataset):\n",
    "    \"\"\"Obtain the c1 itemsets from dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset: list of lists containing items\n",
    "    Returns:\n",
    "        list of frozensets as itemsets, sorted in ascending order\n",
    "    \"\"\"\n",
    "    c1 = []\n",
    "    \n",
    "    for data in dataset:\n",
    "        for item in data:\n",
    "            if [item] not in c1:\n",
    "                c1.append([item])\n",
    "    \n",
    "    c1.sort()\n",
    "    return list(map(frozenset, c1))\n",
    "\n",
    "def scan_dataset(dataset, cad, min_support):\n",
    "    \"\"\"Scan the dataset to calculate the support of each itemset in candidate \n",
    "        and select the itemsets above min_support.\n",
    "\n",
    "    Args:\n",
    "        dataset: list of lists containing items\n",
    "        cad: candidate list, list of frozensets as itemsets\n",
    "        min_support: minimum support value\n",
    "    Returns:\n",
    "        item_list: list of itemsets that are above min_support\n",
    "        support_dict: dict containing each item in candidate and their support\n",
    "    \"\"\"\n",
    "    item_cnt = {}\n",
    "    for data in dataset:\n",
    "        for item in cad:\n",
    "            if item.issubset(data):\n",
    "                item_cnt[item] = item_cnt.get(item, 0) + 1\n",
    "\n",
    "    num_items = len(dataset)\n",
    "    item_list = []\n",
    "    support_dict = {}\n",
    "\n",
    "    for item, cnt in item_cnt.items():\n",
    "        support = cnt / num_items\n",
    "        support_dict[item] = support\n",
    "\n",
    "        if support >= min_support:\n",
    "            item_list.append(item)\n",
    "        \n",
    "    return item_list, support_dict\n",
    "\n",
    "def generate_candidate(item_list, k):\n",
    "    \"\"\"Generate the candidate list of itemsets with each itemset containing k items from item_list.\n",
    "    \n",
    "    Args:\n",
    "        item_list: list of itemsets that are above min_support\n",
    "        k: number of items in a itemset in candidate list\n",
    "    Returns:\n",
    "        cad: candidate list of frozensets as itemsets\n",
    "    \"\"\"\n",
    "    cad = []\n",
    "    num = len(item_list)\n",
    "    \n",
    "    for i in range(num):\n",
    "        for j in range(i + 1, num):\n",
    "            # use aprior principle, if a set is not frequent then it's superset is not frequent\n",
    "            # k-2: only the last different numbers of two sets are picked to form the new itemset\n",
    "            l1 = list(item_list[i])[:k-2]\n",
    "            l2 = list(item_list[j])[:k-2]\n",
    "\n",
    "            l1.sort()\n",
    "            l2.sort()\n",
    "            if l1 == l2:\n",
    "                cad.append(item_list[i] | item_list[j])\n",
    "    \n",
    "    return cad\n",
    "\n",
    "def apriori(dataset, min_support=0.5):\n",
    "    \"\"\"Use apriori principle to obtain the frequent itemsets and their supports.\n",
    "    \n",
    "    Args:\n",
    "        dataset: list of sets containing items\n",
    "        min_support: minimum support value\n",
    "    Returns:\n",
    "        item_list: list of itemsets that are above min_support\n",
    "        sup_dict: dict containing each item in candidate and their support\n",
    "    \"\"\"\n",
    "    c1 = get_c1(dataset)\n",
    "    l_1, sup_dict = scan_dataset(dataset, c1, min_support)\n",
    "\n",
    "    item_list = [l_1]\n",
    "    i = 0\n",
    "    \n",
    "    while len(item_list[i]) > 1:\n",
    "        c_k = generate_candidate(item_list[i], i + 2)\n",
    "        l_k, sup_dict_k = scan_dataset(dataset, c_k, min_support)\n",
    "    \n",
    "        item_list.append(l_k)\n",
    "        sup_dict.update(sup_dict_k)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return item_list, sup_dict\n",
    "\n",
    "\n",
    "def calculate_confidence(freq_set, conseq_list, support_dict, rule_list, min_confidence):\n",
    "    \"\"\"Calculate the confidence of frequent set to consequent and update the rule list.\n",
    "    \n",
    "    Args:\n",
    "        freq_set: a set containing frequent itemsets\n",
    "        conseq_list: list of frozensets as consequents\n",
    "        support_dict: dict containing each item in candidate and their support\n",
    "        rule_list: list containing (antecedent, consequent, confident)\n",
    "        min_confidence: minimum confidence allowed\n",
    "    Returns:\n",
    "        pruned_list: pruned consequent list\n",
    "    \"\"\"\n",
    "    pruned_list = []\n",
    "\n",
    "    for item in conseq_list:\n",
    "        confidence = support_dict[freq_set] / support_dict[freq_set - item]\n",
    "        if confidence >= min_confidence:\n",
    "            rule_list.append((freq_set - item, item, confidence))\n",
    "            pruned_list.append(item)\n",
    "\n",
    "    return pruned_list\n",
    "\n",
    "def merge_consequents(freq_set, conseq_list, support_dict, rule_list, min_confidence):\n",
    "    n = len(conseq_list)\n",
    "\n",
    "    if len(freq_set) > n + 1:   # ensure antecedents are more than consequents\n",
    "        new_conseq_list = generate_candidate(conseq_list, n + 1)\n",
    "        new_conseq_list = calculate_confidence(freq_set, new_conseq_list, support_dict, rule_list, min_confidence)\n",
    "\n",
    "        if len(new_conseq_list) > 1:    # further merge if more than 2 consequents\n",
    "            merge_consequents(freq_set, conseq_list, support_dict, rule_list, min_confidence)\n",
    "\n",
    "def generate_rules(freq_list, support_dict, min_confidence=0.7):\n",
    "    \"\"\"Generate associate rules for all frequent sets.\n",
    "    \n",
    "    Args:\n",
    "        freq_list: list of fronzensets as frequent sets\n",
    "        support_dict: dict containing each item in candidate and their support\n",
    "        min_confidence: minimum confidence allowed\n",
    "    Returns:\n",
    "        rule_list: list containing (antecedent, consequent, confident)\n",
    "    \"\"\"\n",
    "    rule_list = []\n",
    "\n",
    "    for i in range(1, len(freq_list)):      # freq_list[0] only contains 1 item set\n",
    "        for freq_set in freq_list[i]:\n",
    "            \n",
    "            conseq_list = [frozenset([item]) for item in freq_set]\n",
    "            conseq_list = calculate_confidence(freq_set, conseq_list, support_dict, rule_list, min_confidence)\n",
    "\n",
    "            if i > 1:\n",
    "                merge_consequents(freq_set, conseq_list, support_dict, rule_list, min_confidence)\n",
    "\n",
    "    return rule_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_sample_data()\n",
    "l, sup_dict = apriori(dataset, 0.5)\n",
    "rules = generate_rules(l, sup_dict, 0.7)\n",
    "rules2 = generate_rules(l, sup_dict, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({1}), frozenset({3}), frozenset({2}), frozenset({5})],\n",
       " [frozenset({1, 3}), frozenset({2, 3}), frozenset({3, 5}), frozenset({2, 5})],\n",
       " [frozenset({2, 3, 5})]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({1}): 0.5,\n",
       " frozenset({3}): 0.75,\n",
       " frozenset({4}): 0.25,\n",
       " frozenset({2}): 0.75,\n",
       " frozenset({5}): 0.75,\n",
       " frozenset({1, 3}): 0.5,\n",
       " frozenset({2, 3}): 0.5,\n",
       " frozenset({3, 5}): 0.5,\n",
       " frozenset({2, 5}): 0.75,\n",
       " frozenset({1, 2}): 0.25,\n",
       " frozenset({1, 5}): 0.25,\n",
       " frozenset({2, 3, 5}): 0.5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({1}), frozenset({3}), 1.0),\n",
       " (frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({3, 5}), frozenset({2}), 1.0),\n",
       " (frozenset({2, 3}), frozenset({5}), 1.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({3}), frozenset({1}), 0.6666666666666666),\n",
       " (frozenset({1}), frozenset({3}), 1.0),\n",
       " (frozenset({3}), frozenset({2}), 0.6666666666666666),\n",
       " (frozenset({2}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({5}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({3}), frozenset({5}), 0.6666666666666666),\n",
       " (frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({3, 5}), frozenset({2}), 1.0),\n",
       " (frozenset({2, 5}), frozenset({3}), 0.6666666666666666),\n",
       " (frozenset({2, 3}), frozenset({5}), 1.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
